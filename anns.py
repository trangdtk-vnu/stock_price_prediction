# -*- coding: utf-8 -*-
"""anns.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bK23QThSaqSJtoWL_wiEGyfb6bGdVYzc
"""

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
import torch
import torch.nn as nn
import torch.optim as optim
from copy import deepcopy
import random
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import copy
from scipy.stats import truncnorm
from torch.optim import Adam
from torch.nn import MSELoss
from torch.utils.data import TensorDataset
from torch.nn.functional import mse_loss as MSELoss
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

"""# custom_loss function"""

class EnhancedSignAgreementLoss(nn.Module):
    def __init__(self, loss_penalty):
        super(EnhancedSignAgreementLoss, self).__init__()
        self.loss_penalty = loss_penalty

    def forward(self, y_true, y_pred):
        # Check if signs of y_true and y_pred are the same (including zero)
        same_sign = torch.eq(torch.sign(y_true), torch.sign(y_pred))

        # Calculate the residual (difference between y_true and y_pred)
        residual = y_true - y_pred

        # Compute the loss based on the condition
        loss = torch.where(same_sign,
                           torch.square(residual),
                           torch.square(residual) + self.loss_penalty)

        # Return the mean loss
        return torch.mean(loss)

"""# RMSE"""

# Define RMSE loss function
class RMSELoss(nn.Module):
    def __init__(self):
        super().__init__()
        self.mse = nn.MSELoss()

    def forward(self, pred, actual):
        return torch.sqrt(self.mse(pred, actual))

"""# Create sequence"""

# Create sequences for RNNs
def create_sequences_rnns(X, y, time_steps):
    #create an empty list to store inputs and outputs
    Xs, ys = [], []
    # loop through the array to the end minus the number of time steps
    # - time_steps in the loop is to ensure that each input sequence created has
    # a corresponding future data point
    for i in range(len(X) - time_steps):
        Xs.append(X[i:(i + time_steps)])
        ys.append(y[i + time_steps])
    return np.array(Xs), np.array(ys)

"""# RNNs architecture"""

# Define a simple RNN class and initialize it with __init__ with needed parameters
class SimpleRNN(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(SimpleRNN, self).__init__()
        # batch_first = True means that the input tensor will have batch size as first dimension

        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
        # define a fully connected layer to transform the output from the RNN
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.rnn(x)  # Outputs from all timesteps
        out = self.fc(out[:, -1, :])  # Last timestep output to fully connected layer
        return out.squeeze()  # Remove extra dimension to match target shape

def rnns(model, train_loader, val_loader, epochs, optimizer, loss_function):
    best_val_loss = float('inf') # initialize best validation loss to infity for comparison
    best_model_state = None #variable to store the best model
    # loop for n training epochs
    for epoch in range(epochs):
        model.train()
        #iterate over each batch in training dataset
        for inputs, labels in train_loader:
            optimizer.zero_grad() # clear gradients before computing them
            outputs = model(inputs) #generate predictions
            if outputs.dim() > 1 and outputs.shape[1] == 1:
                outputs = outputs.squeeze(1)
            #Calculate the loss, apply backpropagation to compute gradients and uodate weights
            loss = loss_function(outputs, labels)
            loss.backward()
            optimizer.step()

        model.eval() #evaluate the model (disables dropout etc.)
        total_val_loss = 0
        #do not compute gradients
        with torch.no_grad():
            for inputs, labels in val_loader:
                outputs = model(inputs)
                if outputs.dim() > 1 and outputs.shape[1] == 1:
                    outputs = outputs.squeeze(1)
                val_loss = loss_function(outputs, labels)
                total_val_loss += val_loss

        avg_val_loss = total_val_loss / len(val_loader) #calculate the average loss for each epoch
        #check if avg loss is the best and update it if needed
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            best_model_state = model.state_dict()  # Save the best model state

        if epoch % 10 == 0:
            #print progress every 10 epochs
            print(f'Epoch {epoch+1}, Train Loss: {loss.item()}, Val Loss: {avg_val_loss}')

    return best_model_state, best_val_loss

"""# LSTM"""

class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(LSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        # Initialize hidden and cell states
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)

        # Forward propagate LSTM
        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)

        # Decode the hidden state of the last time step
        out = self.fc(out[:, -1, :])
        return out

def lstm(model, train_loader, val_loader, epochs, optimizer, loss_function):
    """
    Trains an LSTM model and evaluates it on a validation set.

    Args:
        model (torch.nn.Module): The LSTM model to train.
        train_loader (DataLoader): DataLoader for the training set.
        val_loader (DataLoader): DataLoader for the validation set.
        epochs (int): Number of epochs to train.
        optimizer (torch.optim.Optimizer): Optimizer to use for training.
        loss_function (callable): Loss function to use for training.

    Returns:
        tuple: Tuple containing the state_dict of the best model (by validation loss)
               and the best validation loss observed.
    """
    best_val_loss = float('inf')
    best_model = None

    for epoch in range(epochs):
        model.train()
        total_train_loss = 0
        for inputs, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            outputs = outputs.squeeze()  # Adjusting dimensions to match labels
            loss = loss_function(outputs, labels)
            loss.backward()
            optimizer.step()
            total_train_loss += loss.item()

        avg_train_loss = total_train_loss / len(train_loader)

        model.eval()
        total_val_loss = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                outputs = model(inputs)
                outputs = outputs.squeeze()  # Adjusting dimensions to match labels
                val_loss = loss_function(outputs, labels).item()
                total_val_loss += val_loss

        avg_val_loss = total_val_loss / len(val_loader)
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            best_model = model.state_dict()  # Update the best model to the current state

        if epoch % 10 == 0:
            print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}')

    # Communicate final best validation loss and return the best model
    print(f'Final Best Validation Loss: {best_val_loss}')
    return best_model, best_val_loss

"""# Sign comparision function"""

def evaluate_signs(model, data_loader):
    model.eval()
    all_predicted_labels = []
    all_actual_labels = []

    with torch.no_grad():
        for inputs, labels in data_loader:
            outputs = model(inputs)
            outputs = outputs.squeeze()  # Ensure outputs match expected dimensions for comparison

            # Convert outputs and labels to binary based on sign
            predicted_labels = (outputs >= 0).int()
            actual_labels = (labels >= 0).int()

            all_predicted_labels.extend(predicted_labels.tolist())
            all_actual_labels.extend(actual_labels.tolist())

    # Calculate classification metrics
    accuracy = accuracy_score(all_actual_labels, all_predicted_labels)
    precision = precision_score(all_actual_labels, all_predicted_labels)
    recall = recall_score(all_actual_labels, all_predicted_labels)
    f1 = f1_score(all_actual_labels, all_predicted_labels)

    return accuracy, precision, recall, f1